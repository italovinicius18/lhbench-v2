# LHBench TPC-H Benchmark - VersÃ£o Standalone

Uma versÃ£o completamente independente do LHBench que executa o benchmark TPC-H sem depender do Airflow.

## ðŸš€ CaracterÃ­sticas

- **Zero dependÃªncia do Airflow**: ExecuÃ§Ã£o direta em Python
- **Pipeline completo**: Bronze â†’ Silver â†’ Gold (Benchmark)
- **MÃºltiplos formatos**: Delta Lake, Apache Iceberg, Apache Hudi
- **ConfiguraÃ§Ã£o simples**: Via variÃ¡veis de ambiente ou cÃ³digo
- **Logs estruturados**: Acompanhamento detalhado do progresso
- **ExecuÃ§Ã£o flexÃ­vel**: Pipeline completo ou etapas individuais

## ðŸ“‹ PrÃ©-requisitos

### Infraestrutura
- **MinIO** ou S3 compatÃ­vel rodando
- **Buckets criados**: `bronze`, `silver`, `gold`
- **Java 11+** para Apache Spark

### Python
- **Python 3.8+**
- **MemÃ³ria**: MÃ­nimo 8GB RAM (recomendado 16GB+ para SF > 10)

## ðŸ”§ InstalaÃ§Ã£o

### 1. Instalar dependÃªncias

```bash
# Instalar dependÃªncias essenciais
pip install -r requirements-standalone.txt

# Ou instalar individualmente
pip install duckdb pyspark boto3 pandas pyarrow delta-spark
```

### 2. Configurar ambiente

```bash
# ConfiguraÃ§Ãµes MinIO/S3
export MINIO_ENDPOINT="http://localhost:9000"
export MINIO_ACCESS_KEY="minioadmin"
export MINIO_SECRET_KEY="minioadmin"

# ConfiguraÃ§Ãµes TPC-H
export SCALE_FACTOR=10
export BENCHMARK_ITERATIONS=3

# ConfiguraÃ§Ãµes Spark (opcional)
export SPARK_EXECUTOR_MEMORY="4g"
export SPARK_DRIVER_MEMORY="2g"
```

### 3. Verificar conectividade

```python
# Teste rÃ¡pido
from standalone.utils import get_s3_client

s3 = get_s3_client()
buckets = s3.list_buckets()
print("Buckets:", [b['Name'] for b in buckets['Buckets']])
```

## ðŸŽ¯ Uso RÃ¡pido

### Pipeline Completo

```bash
# ExecuÃ§Ã£o completa - SF=10, todos os formatos
python -m standalone.main

# Scale Factor personalizado
python -m standalone.main --scale-factor 1

# Apenas Delta Lake para teste rÃ¡pido
python -m standalone.main --formats delta --iterations 1
```

### Etapas Individuais

```bash
# Apenas geraÃ§Ã£o Bronze
python -m standalone.main --bronze-only

# Apenas conversÃ£o Silver
python -m standalone.main --silver-only --formats delta iceberg

# Apenas Benchmark
python -m standalone.main --benchmark-only
```

### Uso ProgramÃ¡tico

```python
from standalone import run_full_pipeline

# Pipeline completo
results = run_full_pipeline(
    scale_factor=10,
    benchmark_formats=["delta", "iceberg", "hudi"],
    benchmark_iterations=3
)

print(f"Status: {results['status']}")
```

## ðŸ“Š Exemplos PrÃ¡ticos

### Exemplo 1: Teste RÃ¡pido (SF=1, Delta apenas)

```python
from standalone import run_full_pipeline

results = run_full_pipeline(
    scale_factor=1,
    benchmark_formats=["delta"],
    benchmark_iterations=1,
    force_regenerate_bronze=True
)
```

### Exemplo 2: Benchmark Completo

```python
from standalone import run_full_pipeline

results = run_full_pipeline(
    scale_factor=10,
    benchmark_formats=["delta", "iceberg", "hudi"], 
    benchmark_iterations=3
)

# Ver ranking de performance
if results["status"] == "success":
    ranking = results["stages"]["benchmark"]["comparison"]["format_ranking"]
    for i, fmt in enumerate(ranking, 1):
        print(f"{i}. {fmt['format']}: {fmt['overall_avg_time']:.2f}s")
```

### Exemplo 3: Etapas Separadas

```python
from standalone import generate_bronze_data, convert_to_silver_format, benchmark_format

# 1. Gerar dados bronze
bronze_result = generate_bronze_data(scale_factor=1)

# 2. Converter para Delta
silver_result = convert_to_silver_format("delta", scale_factor=1)

# 3. Executar benchmark
benchmark_result = benchmark_format("delta", scale_factor=1, iterations=1)
```

## âš™ï¸ ConfiguraÃ§Ã£o AvanÃ§ada

### Arquivo de ConfiguraÃ§Ã£o

```python
from standalone import LHBenchConfig

config = LHBenchConfig(
    scale_factor=10,
    minio_endpoint="http://minio.local:9000",
    minio_access_key="admin",
    minio_secret_key="password123",
    
    # Spark tuning
    spark_executor_memory="8g",
    spark_driver_memory="4g", 
    spark_executor_cores=4,
    spark_executor_instances=3,
    
    # Benchmark settings
    benchmark_formats=["delta", "iceberg"],
    benchmark_iterations=5,
    timeout_minutes=60,
    
    # Output
    results_path="./results",
    save_detailed_results=True
)
```

### ConfiguraÃ§Ã£o por VariÃ¡veis de Ambiente

```bash
# TPC-H
export SCALE_FACTOR=100
export BENCHMARK_ITERATIONS=5
export BENCHMARK_FORMATS="delta,iceberg,hudi"

# MinIO/S3
export MINIO_ENDPOINT="http://s3.amazonaws.com"
export MINIO_ACCESS_KEY="AKIAIOSFODNN7EXAMPLE"  
export MINIO_SECRET_KEY="wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
export BRONZE_BUCKET="tpch-bronze"
export SILVER_BUCKET="tpch-silver"
export GOLD_BUCKET="tpch-gold"

# Spark
export SPARK_EXECUTOR_MEMORY="16g"
export SPARK_DRIVER_MEMORY="8g"
export SPARK_EXECUTOR_CORES=8
export SPARK_EXECUTOR_INSTANCES=4
```

## ðŸ“ˆ Monitoramento e Resultados

### Logs Estruturados

```
2025-09-29 14:30:15 | lhbench | INFO | ðŸš€ Iniciando GeraÃ§Ã£o TPC-H Bronze
2025-09-29 14:30:16 | lhbench | INFO | âœ… ExtensÃ£o TPC-H carregada
2025-09-29 14:30:20 | lhbench | INFO |    âœ… customer: 150,000 linhas â†’ s3://bronze/sf_1/parquet/customer/
2025-09-29 14:30:25 | lhbench | INFO |    âœ… lineitem: 6,001,215 linhas â†’ s3://bronze/sf_1/parquet/lineitem/
2025-09-29 14:30:30 | lhbench | INFO | âœ… GeraÃ§Ã£o TPC-H Bronze concluÃ­da em 15.2s
```

### Resultados Salvos

Os resultados sÃ£o salvos automaticamente:

- **Local**: `./results/` (JSON detalhado)
- **S3/MinIO**: `s3://gold/benchmark_results/` 

Estrutura dos resultados:
```
results/
â”œâ”€â”€ bronze_generation_20250929_143015.json
â”œâ”€â”€ silver_conversion_delta_20250929_143045.json
â”œâ”€â”€ benchmark_delta_20250929_143200.json
â””â”€â”€ benchmark_complete_20250929_143300.json
```

### MÃ©tricas de Performance

```json
{
  "comparison": {
    "format_ranking": [
      {
        "format": "delta",
        "overall_avg_time": 45.32,
        "successful_queries": 22,
        "total_queries": 22
      },
      {
        "format": "iceberg", 
        "overall_avg_time": 52.18,
        "successful_queries": 22,
        "total_queries": 22
      }
    ],
    "best_format": "delta"
  }
}
```

## ðŸ”§ Troubleshooting

### Problema: Erro de memÃ³ria Spark

```bash
# Aumentar memÃ³ria
export SPARK_EXECUTOR_MEMORY="8g"
export SPARK_DRIVER_MEMORY="4g"

# Ou reduzir Scale Factor
python -m standalone.main --scale-factor 1
```

### Problema: Timeout nas queries

```bash
# Aumentar timeout
python -m standalone.main --timeout-minutes 60
```

### Problema: MinIO nÃ£o conecta

```python
# Verificar conectividade
from standalone.utils import get_s3_client

try:
    s3 = get_s3_client()
    response = s3.list_buckets()
    print("âœ… MinIO conectado")
except Exception as e:
    print(f"âŒ Erro MinIO: {e}")
```

### Problema: DependÃªncias Spark

```bash
# Verificar Java
java -version

# Reinstalar PySpark
pip uninstall pyspark
pip install pyspark==3.5.5
```

## ðŸ“š Estrutura do CÃ³digo

```
standalone/
â”œâ”€â”€ __init__.py              # API pÃºblica
â”œâ”€â”€ config.py               # ConfiguraÃ§Ãµes centralizadas
â”œâ”€â”€ utils.py                # UtilitÃ¡rios comuns
â”œâ”€â”€ bronze_generator.py     # GeraÃ§Ã£o dados TPC-H (DuckDB)
â”œâ”€â”€ silver_converter.py     # ConversÃ£o Bronzeâ†’Silver (Spark)
â”œâ”€â”€ benchmark_executor.py   # Benchmark 22 queries (Spark)
â”œâ”€â”€ tpch_queries.py        # Queries TPC-H padrÃ£o
â””â”€â”€ main.py                # Script principal CLI
```

## ðŸš¦ Comandos CLI Completos

```bash
# Ajuda
python -m standalone.main --help

# Pipeline completo com opÃ§Ãµes
python -m standalone.main \
  --scale-factor 10 \
  --formats delta iceberg hudi \
  --iterations 3 \
  --force-bronze \
  --log-level INFO

# Apenas uma etapa
python -m standalone.main --bronze-only --scale-factor 1
python -m standalone.main --silver-only --formats delta
python -m standalone.main --benchmark-only --iterations 1

# Pular etapas
python -m standalone.main --skip-bronze --skip-silver  # SÃ³ benchmark
python -m standalone.main --skip-benchmark             # Bronze + Silver
```

## ðŸŽ¯ Performance Tips

### Para Scale Factors Grandes (SF >= 100)

```bash
# ConfiguraÃ§Ã£o robusta
export SPARK_EXECUTOR_MEMORY="16g"
export SPARK_DRIVER_MEMORY="8g"
export SPARK_EXECUTOR_CORES=8
export SPARK_EXECUTOR_INSTANCES=6

# Executar com timeout maior
python -m standalone.main --scale-factor 100 --timeout-minutes 120
```

### Para Testes RÃ¡pidos

```bash
# ConfiguraÃ§Ã£o mÃ­nima
python -m standalone.main \
  --scale-factor 1 \
  --formats delta \
  --iterations 1 \
  --force-bronze
```

### Para MÃ¡xima Performance

```bash
# Usar cluster Spark externo com configuraÃ§Ã£o otimizada
export SPARK_MASTER="spark://cluster:7077"
export SPARK_EXECUTOR_INSTANCES=10
export SPARK_EXECUTOR_MEMORY="32g"
export SPARK_EXECUTOR_CORES=16
```

---

## ðŸ”— MigraÃ§Ã£o do Airflow

Se vocÃª estava usando a versÃ£o com Airflow, a migraÃ§Ã£o Ã© simples:

**Antes (Airflow)**:
```python
from airflow import DAG
from airflow.operators.trigger_dagrun import TriggerDagRunOperator

# DAG complexo com dependÃªncias...
```

**Depois (Standalone)**:
```python
from standalone import run_full_pipeline

# Uma linha!
results = run_full_pipeline(scale_factor=10)
```

**Vantagens da versÃ£o standalone**:
- âœ… Zero overhead do Airflow
- âœ… ExecuÃ§Ã£o mais rÃ¡pida
- âœ… Debugging simplificado  
- âœ… Deploy mais fÃ¡cil
- âœ… Menos dependÃªncias
- âœ… Controle total do fluxo
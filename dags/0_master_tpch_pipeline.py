from airflow.decorators import dag, task
from datetime import datetime
from airflow.operators.trigger_dagrun import TriggerDagRunOperator
from airflow.sdk import Variable

@dag(
    dag_id="0_master_tpch_pipeline",
    start_date=datetime(2025, 1, 1),
    schedule=None,  # Execu√ß√£o manual apenas
    catchup=False,
    tags=["tpch", "master", "orchestrator", "pipeline", "end-to-end"],
    max_active_runs=1,
    description="DAG orquestradora que executa todo o pipeline TPC-H de forma completamente linear",
    params={
        "scale_factor": 10,
        "input_format": "csv",  # csv ou parquet
        "force_regenerate_bronze": False,
        "force_recreate_silver": False,
        "run_benchmark": True,
        "benchmark_formats": ["delta", "iceberg", "hudi"],
        "benchmark_iterations": 3,
        "cleanup_on_failure": False
    },
)
def master_tpch_pipeline():
    """
    DAG Master que orquestra todo o pipeline TPC-H de forma linear:
    1. Gera√ß√£o de dados bronze (TPC-H)
    2. Convers√£o para silver Delta
    3. Convers√£o para silver Iceberg  
    4. Convers√£o para silver Hudi
    5. Benchmark das 22 queries TPC-H
    6. Relat√≥rio final consolidado
    """

    @task
    def validate_pipeline_parameters(**context):
        """Valida os par√¢metros do pipeline e configura√ß√µes"""
        
        params = context["params"]
        scale_factor = params.get("scale_factor", 10)
        input_format = params.get("input_format", "csv")
        benchmark_formats = params.get("benchmark_formats", ["delta", "iceberg", "hudi"])
        
        print(f"üîç Validando par√¢metros do pipeline TPC-H")
        print(f"üìä Scale Factor: {scale_factor}")
        print(f"üìÑ Formato de entrada: {input_format}")
        print(f"üéØ Formatos para benchmark: {benchmark_formats}")
        
        # Valida√ß√µes
        if scale_factor < 1:
            raise ValueError("Scale factor deve ser >= 1")
        
        if input_format not in ["csv", "parquet"]:
            raise ValueError("Formato deve ser 'csv' ou 'parquet'")
        
        valid_formats = ["delta", "iceberg", "hudi"]
        invalid_formats = [f for f in benchmark_formats if f not in valid_formats]
        if invalid_formats:
            raise ValueError(f"Formatos inv√°lidos: {invalid_formats}. V√°lidos: {valid_formats}")
        
        # Verificar conectividade MinIO
        try:
            import boto3
            from botocore.exceptions import ClientError
            
            s3_client = boto3.client(
                's3',
                endpoint_url=Variable.get("MINIO_ENDPOINT"),
                aws_access_key_id=Variable.get("MINIO_ACCESS_KEY"),
                aws_secret_access_key=Variable.get("MINIO_SECRET_KEY")
            )
            
            # Testar conectividade
            s3_client.list_buckets()
            print("‚úÖ Conectividade MinIO validada")
            
            # Verificar buckets necess√°rios
            required_buckets = ["bronze", "silver", "gold"]
            existing_buckets = [b['Name'] for b in s3_client.list_buckets()['Buckets']]
            
            for bucket in required_buckets:
                if bucket not in existing_buckets:
                    print(f"‚ö†Ô∏è Criando bucket ausente: {bucket}")
                    try:
                        s3_client.create_bucket(Bucket=bucket)
                        print(f"‚úÖ Bucket {bucket} criado")
                    except ClientError as e:
                        if e.response['Error']['Code'] != 'BucketAlreadyOwnedByYou':
                            raise
                else:
                    print(f"‚úÖ Bucket {bucket} dispon√≠vel")
            
        except Exception as e:
            print(f"‚ùå Erro na valida√ß√£o MinIO: {str(e)}")
            raise
        
        print("üéâ Valida√ß√£o do pipeline conclu√≠da com sucesso!")
        
        return {
            "validation_status": "success",
            "scale_factor": scale_factor,
            "input_format": input_format,
            "benchmark_formats": benchmark_formats,
            "pipeline_start_time": datetime.now().isoformat()
        }

    @task
    def generate_pipeline_report(validation_result: dict, **context):
        """Gera relat√≥rio inicial do pipeline"""
        
        params = context["params"]
        
        print(f"üìã RELAT√ìRIO INICIAL - PIPELINE TPC-H MASTER")
        print(f"=" * 60)
        print(f"üìÖ Data/Hora de in√≠cio: {validation_result['pipeline_start_time']}")
        print(f"üìä Scale Factor: {validation_result['scale_factor']}")
        print(f"üìÑ Formato de entrada: {validation_result['input_format']}")
        print(f"üéØ Formatos benchmark: {', '.join(validation_result['benchmark_formats'])}")
        print(f"")
        print(f"üìã Etapas do Pipeline:")
        print(f"   1Ô∏è‚É£ Gera√ß√£o Bronze (TPC-H)")
        print(f"   2Ô∏è‚É£ Convers√£o Silver (Delta)")
        print(f"   3Ô∏è‚É£ Convers√£o Silver (Iceberg)")  
        print(f"   4Ô∏è‚É£ Convers√£o Silver (Hudi)")
        print(f"   5Ô∏è‚É£ Benchmark Gold (22 queries)")
        print(f"   6Ô∏è‚É£ Relat√≥rio Final")
        print(f"")
        print(f"‚öôÔ∏è Configura√ß√µes:")
        print(f"   üîÑ Force regenerate bronze: {params.get('force_regenerate_bronze', False)}")
        print(f"   üîÑ Force recreate silver: {params.get('force_recreate_silver', False)}")
        print(f"   üìä Benchmark iterations: {params.get('benchmark_iterations', 3)}")
        print(f"=" * 60)
        
        return validation_result

    # 1Ô∏è‚É£ ETAPA 1: Gera√ß√£o de dados bronze TPC-H
    trigger_bronze = TriggerDagRunOperator(
        task_id="trigger_bronze_generation",
        trigger_dag_id="1_generate_bronze_tpch",
        conf={
            "scale_factor": "{{ params.scale_factor }}",
            "output_format": "{{ params.input_format }}",
            "force_regenerate": "{{ params.force_regenerate_bronze }}",
            "parallel_children": 5
        },
        wait_for_completion=True,
        poke_interval=30,
        allowed_states=['success'],
        failed_states=['failed']
    )

    # 2Ô∏è‚É£ ETAPA 2: Convers√£o Bronze ‚Üí Silver Delta
    trigger_silver_delta = TriggerDagRunOperator(
        task_id="trigger_silver_delta",
        trigger_dag_id="2_bronze_to_silver_delta",
        conf={
            "scale_factor": "{{ params.scale_factor }}",
            "input_format": "{{ params.input_format }}",
            "force_recreate": "{{ params.force_recreate_silver }}",
            "validate_data": True
        },
        wait_for_completion=True,
        poke_interval=30,
        allowed_states=['success'],
        failed_states=['failed']
    )

    # 3Ô∏è‚É£ ETAPA 3: Convers√£o Bronze ‚Üí Silver Iceberg  
    trigger_silver_iceberg = TriggerDagRunOperator(
        task_id="trigger_silver_iceberg",
        trigger_dag_id="2_bronze_to_silver_iceberg",
        conf={
            "scale_factor": "{{ params.scale_factor }}",
            "input_format": "{{ params.input_format }}",
            "force_recreate": "{{ params.force_recreate_silver }}",
            "validate_data": True
        },
        wait_for_completion=True,
        poke_interval=30,
        allowed_states=['success'],
        failed_states=['failed']
    )

    # 4Ô∏è‚É£ ETAPA 4: Convers√£o Bronze ‚Üí Silver Hudi
    trigger_silver_hudi = TriggerDagRunOperator(
        task_id="trigger_silver_hudi",
        trigger_dag_id="2_bronze_to_silver_hudi",
        conf={
            "scale_factor": "{{ params.scale_factor }}",
            "input_format": "{{ params.input_format }}",
            "force_recreate": "{{ params.force_recreate_silver }}",
            "validate_data": True
        },
        wait_for_completion=True,
        poke_interval=30,
        allowed_states=['success'],
        failed_states=['failed']
    )

    # Sensor para aguardar todas as convers√µes silver
    @task
    def validate_silver_completion(**context):
        """Valida que todas as convers√µes silver foram conclu√≠das"""
        
        params = context["params"]
        scale_factor = params.get("scale_factor", 10)
        
        print(f"üîç Validando conclus√£o das convers√µes Silver")
        print(f"üìä Verificando dados para SF {scale_factor}")
        
        try:
            import boto3
            from botocore.exceptions import ClientError
            
            s3_client = boto3.client(
                's3',
                endpoint_url=Variable.get("MINIO_ENDPOINT"),
                aws_access_key_id=Variable.get("MINIO_ACCESS_KEY"),
                aws_secret_access_key=Variable.get("MINIO_SECRET_KEY")
            )
            
            formats = ["delta", "iceberg", "hudi"]
            tables = ["customer", "lineitem", "nation", "orders", "part", "partsupp", "region", "supplier"]
            
            validation_results = {}
            
            for format_name in formats:
                format_tables_found = 0
                for table in tables:
                    prefix = f"sf_{scale_factor}/{format_name}/{table}/"
                    
                    try:
                        response = s3_client.list_objects_v2(
                            Bucket="silver",
                            Prefix=prefix,
                            MaxKeys=1
                        )
                        
                        if 'Contents' in response and len(response['Contents']) > 0:
                            format_tables_found += 1
                            
                    except ClientError:
                        pass
                
                validation_results[format_name] = {
                    "tables_found": format_tables_found,
                    "tables_expected": len(tables),
                    "complete": format_tables_found == len(tables)
                }
                
                status = "‚úÖ" if format_tables_found == len(tables) else "‚ùå"
                print(f"   {status} {format_name}: {format_tables_found}/{len(tables)} tabelas")
            
            # Verificar se todos os formatos est√£o completos
            all_complete = all(r["complete"] for r in validation_results.values())
            
            if all_complete:
                print(f"‚úÖ Todas as convers√µes Silver conclu√≠das com sucesso!")
                return {
                    "validation_status": "success",
                    "formats_ready": list(validation_results.keys()),
                    "validation_results": validation_results
                }
            else:
                incomplete_formats = [f for f, r in validation_results.items() if not r["complete"]]
                raise Exception(f"Formatos incompletos: {incomplete_formats}")
                
        except Exception as e:
            print(f"‚ùå Erro na valida√ß√£o Silver: {str(e)}")
            raise

    # 5Ô∏è‚É£ ETAPA 5: Benchmark TPC-H nas 22 queries
    @task 
    def trigger_benchmark_conditionally(**context):
        """Dispara benchmark apenas se habilitado"""
        
        params = context["params"]
        run_benchmark = params.get("run_benchmark", True)
        
        if not run_benchmark:
            print("‚è≠Ô∏è Benchmark desabilitado via par√¢metro")
            return {"status": "skipped", "reason": "disabled_by_parameter"}
        
        print("üöÄ Preparando execu√ß√£o do benchmark...")
        return {"status": "ready_for_benchmark"}

    trigger_benchmark = TriggerDagRunOperator(
        task_id="trigger_tpch_benchmark",
        trigger_dag_id="6_tpch_benchmark_gold",
        conf={
            "scale_factor": "{{ params.scale_factor }}",
            "test_formats": "{{ params.benchmark_formats }}",
            "iterations": "{{ params.benchmark_iterations }}",
            "run_warmup": True,
            "timeout_minutes": 30,
            "save_results": True
        },
        wait_for_completion=True,
        poke_interval=60,
        allowed_states=['success'],
        failed_states=['failed']
    )

    # 6Ô∏è‚É£ ETAPA 6: Relat√≥rio Final do Pipeline
    @task
    def generate_final_report(validation_result: dict, silver_validation: dict, **context):
        """Gera relat√≥rio final consolidado do pipeline"""
        
        params = context["params"]
        pipeline_end_time = datetime.now()
        pipeline_start_time = datetime.fromisoformat(validation_result["pipeline_start_time"])
        total_duration = pipeline_end_time - pipeline_start_time
        
        print(f"\nüéâ RELAT√ìRIO FINAL - PIPELINE TPC-H MASTER")
        print(f"=" * 70)
        print(f"üìÖ In√≠cio: {pipeline_start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"üìÖ Fim: {pipeline_end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"‚è±Ô∏è Dura√ß√£o total: {total_duration}")
        print(f"")
        print(f"üìä Configura√ß√£o do Pipeline:")
        print(f"   ‚Ä¢ Scale Factor: {validation_result['scale_factor']}")
        print(f"   ‚Ä¢ Formato: {validation_result['input_format']}")
        print(f"   ‚Ä¢ Formatos benchmark: {', '.join(validation_result['benchmark_formats'])}")
        print(f"")
        print(f"‚úÖ Etapas Conclu√≠das:")
        print(f"   1Ô∏è‚É£ Gera√ß√£o Bronze TPC-H: ‚úÖ")
        print(f"   2Ô∏è‚É£ Convers√£o Silver Delta: ‚úÖ")
        print(f"   3Ô∏è‚É£ Convers√£o Silver Iceberg: ‚úÖ") 
        print(f"   4Ô∏è‚É£ Convers√£o Silver Hudi: ‚úÖ")
        
        if params.get("run_benchmark", True):
            print(f"   5Ô∏è‚É£ Benchmark 22 Queries TPC-H: ‚úÖ")
        else:
            print(f"   5Ô∏è‚É£ Benchmark TPC-H: ‚è≠Ô∏è (Desabilitado)")
        
        print(f"")
        print(f"üìä Resultados Silver:")
        for format_name, result in silver_validation["validation_results"].items():
            status = "‚úÖ" if result["complete"] else "‚ùå"
            print(f"   {status} {format_name.upper()}: {result['tables_found']}/8 tabelas")
        
        print(f"")
        print(f"üíæ Localiza√ß√£o dos Dados:")
        print(f"   üìÇ Bronze: s3://bronze/sf_{validation_result['scale_factor']}/")
        print(f"   üìÇ Silver: s3://silver/sf_{validation_result['scale_factor']}/")
        print(f"   üìÇ Gold: s3://gold/ (resultados benchmark)")
        print(f"")
        print(f"üîó Acesso MinIO: {Variable.get('MINIO_ENDPOINT', 'http://localhost:9001')}")
        print(f"=" * 70)
        
        return {
            "pipeline_status": "completed",
            "start_time": validation_result["pipeline_start_time"],
            "end_time": pipeline_end_time.isoformat(),
            "duration_seconds": total_duration.total_seconds(),
            "scale_factor": validation_result["scale_factor"],
            "formats_completed": list(silver_validation["validation_results"].keys()),
            "benchmark_executed": params.get("run_benchmark", True)
        }

    @task
    def cleanup_on_failure(**context):
        """Limpeza opcional em caso de falha"""
        
        params = context["params"]
        cleanup_enabled = params.get("cleanup_on_failure", False)
        
        if not cleanup_enabled:
            print("üö´ Limpeza autom√°tica desabilitada")
            return {"status": "cleanup_disabled"}
        
        # Implementar limpeza se necess√°rio
        print("üßπ Executando limpeza p√≥s-falha...")
        # Aqui poder√≠amos limpar dados parciais, etc.
        
        return {"status": "cleanup_completed"}

    # üìã DEFINI√á√ÉO DO PIPELINE LINEAR
    
    # Inicializa√ß√£o
    validation_task = validate_pipeline_parameters()
    report_task = generate_pipeline_report(validation_task)
    
    # Bronze (Etapa 1)
    bronze_trigger = trigger_bronze
    
    # Silver (Etapas 2-4) - Executadas de forma linear/sequencial
    silver_delta = trigger_silver_delta
    silver_iceberg = trigger_silver_iceberg  
    silver_hudi = trigger_silver_hudi
    silver_validation_task = validate_silver_completion()
    
    # Benchmark (Etapa 5)
    benchmark_check = trigger_benchmark_conditionally()
    benchmark_trigger = trigger_benchmark
    
    # Finaliza√ß√£o (Etapa 6)
    final_report = generate_final_report(validation_task, silver_validation_task)
    
    # üîó DEPEND√äNCIAS DO PIPELINE
    
    # Inicializa√ß√£o
    validation_task >> report_task >> bronze_trigger
    
    # Bronze ‚Üí Silver (Linear/Sequencial)
    bronze_trigger  >> silver_delta
    silver_delta >> silver_iceberg
    silver_iceberg >> silver_hudi
    
    # Silver ‚Üí Valida√ß√£o
    silver_hudi >> silver_validation_task
    
    # Valida√ß√£o ‚Üí Benchmark
    silver_validation_task >> benchmark_check
    benchmark_check >> benchmark_trigger
    
    # Benchmark ‚Üí Relat√≥rio Final
    benchmark_trigger >> final_report


master_tpch_pipeline()
#!/usr/bin/env python3
"""
Lakehouse Benchmark Report Generator

Generates comprehensive comparison reports from benchmark metrics.
Usage: python scripts/generate_report.py <scale_factor>
Example: python scripts/generate_report.py 3
"""

import json
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional


class BenchmarkReporter:
    def __init__(self, scale_factor: int):
        self.scale_factor = scale_factor
        self.metrics_dir = Path(__file__).parent.parent / "results" / "metrics"
        self.reports_dir = Path(__file__).parent.parent / "results" / "reports"
        self.frameworks = ["delta", "iceberg", "hudi"]
        self.data = {}

    def load_metrics(self) -> bool:
        """Load metrics for all frameworks"""
        print(f"📊 Loading metrics for SF={self.scale_factor}...")

        for framework in self.frameworks:
            # Try both gold and silver metrics
            gold_file = self.metrics_dir / f"gold_{framework}_sf{self.scale_factor}.json"
            silver_file = self.metrics_dir / f"silver_{framework}_sf{self.scale_factor}.json"

            if gold_file.exists():
                with open(gold_file) as f:
                    self.data[framework] = {
                        "gold": json.load(f),
                        "silver": None
                    }
                print(f"   ✓ Loaded {framework} gold metrics")

                if silver_file.exists():
                    with open(silver_file) as f:
                        self.data[framework]["silver"] = json.load(f)
                    print(f"   ✓ Loaded {framework} silver metrics")
            else:
                print(f"   ✗ Missing {framework} gold metrics: {gold_file}")
                return False

        return len(self.data) > 0

    def generate_markdown_report(self) -> str:
        """Generate markdown report"""
        lines = []

        # Header
        lines.append(f"# Lakehouse Benchmark Report - Scale Factor {self.scale_factor}")
        lines.append(f"\n**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"\n**TPC-H Scale Factor:** {self.scale_factor} (~{self.scale_factor}GB)")
        lines.append("\n---\n")

        # Executive Summary
        lines.append("## Executive Summary\n")
        summary_table = self._generate_summary_table()
        lines.append(summary_table)

        # Silver Layer Performance
        if any(self.data[fw].get("silver") for fw in self.frameworks):
            lines.append("\n## Silver Layer Performance (Bronze → Lakehouse Conversion)\n")
            silver_table = self._generate_silver_table()
            lines.append(silver_table)

        # Gold Layer Performance
        lines.append("\n## Gold Layer Performance (Query Execution)\n")

        # Overall statistics
        lines.append("### Overall Statistics\n")
        stats_table = self._generate_stats_table()
        lines.append(stats_table)

        # Query-by-query comparison
        lines.append("\n### Query-by-Query Performance\n")
        query_table = self._generate_query_table()
        lines.append(query_table)

        # Performance analysis
        lines.append("\n### Performance Analysis\n")
        analysis = self._generate_analysis()
        lines.append(analysis)

        # Recommendations
        lines.append("\n## Recommendations\n")
        recommendations = self._generate_recommendations()
        lines.append(recommendations)

        # Footer
        lines.append("\n---\n")
        lines.append("*Report generated by Lakehouse Benchmark Suite*")

        return "\n".join(lines)

    def _generate_summary_table(self) -> str:
        """Generate executive summary table"""
        lines = ["| Framework | Total Time | Avg Query Time | Fastest Queries | Slowest Queries | Rank |"]
        lines.append("|-----------|------------|----------------|-----------------|-----------------|------|")

        results = []
        for framework in self.frameworks:
            gold = self.data[framework]["gold"]
            summary = gold["summary"]

            total_time = summary.get("total_query_time", summary.get("total_execution_time_seconds", 0))
            avg_time = summary.get("average_query_time", summary.get("average_query_time_seconds", 0))

            # Count fastest/slowest - queries is a dict, not list
            queries_dict = gold["queries"]
            queries_list = queries_dict.values() if isinstance(queries_dict, dict) else queries_dict

            fastest = sum(1 for q in queries_list if self._is_fastest(framework, q.get("query_name", q.get("query_id"))))
            slowest = sum(1 for q in queries_list if self._is_slowest(framework, q.get("query_name", q.get("query_id"))))

            results.append({
                "framework": framework.capitalize(),
                "total_time": total_time,
                "avg_time": avg_time,
                "fastest": fastest,
                "slowest": slowest
            })

        # Sort by total time (ascending = better)
        results.sort(key=lambda x: x["total_time"])

        for rank, r in enumerate(results, 1):
            medal = "🥇" if rank == 1 else "🥈" if rank == 2 else "🥉"
            lines.append(
                f"| {r['framework']} | {r['total_time']:.2f}s | {r['avg_time']:.2f}s | "
                f"{r['fastest']} | {r['slowest']} | {medal} #{rank} |"
            )

        return "\n".join(lines)

    def _generate_silver_table(self) -> str:
        """Generate silver layer conversion performance table"""
        lines = ["| Framework | Total Time | Tables Converted | Avg Time/Table | Total Rows |"]
        lines.append("|-----------|------------|------------------|----------------|------------|")

        for framework in self.frameworks:
            silver = self.data[framework].get("silver")
            if not silver:
                continue

            summary = silver.get("summary", {})
            total_time = summary.get("total_conversion_time_seconds", 0)
            num_tables = summary.get("tables_converted", 0)
            avg_time = total_time / num_tables if num_tables > 0 else 0
            total_rows = summary.get("total_rows_converted", 0)

            lines.append(
                f"| {framework.capitalize()} | {total_time:.2f}s | {num_tables} | "
                f"{avg_time:.2f}s | {total_rows:,} |"
            )

        return "\n".join(lines)

    def _generate_stats_table(self) -> str:
        """Generate overall statistics table"""
        lines = ["| Framework | Total Time | Avg Time | Min Time | Max Time | Successful |"]
        lines.append("|-----------|------------|----------|----------|----------|------------|")

        for framework in self.frameworks:
            gold = self.data[framework]["gold"]
            summary = gold["summary"]

            # Get queries as list
            queries_dict = gold["queries"]
            queries_list = list(queries_dict.values()) if isinstance(queries_dict, dict) else queries_dict

            # Calculate min/max from actual queries
            query_times = [q.get("duration_seconds", 0) for q in queries_list if q.get("status") == "success"]
            min_time = min(query_times) if query_times else 0
            max_time = max(query_times) if query_times else 0

            total_time = summary.get("total_query_time", summary.get("total_execution_time_seconds", 0))
            avg_time = summary.get("average_query_time", summary.get("average_query_time_seconds", 0))

            lines.append(
                f"| {framework.capitalize()} | {total_time:.2f}s | "
                f"{avg_time:.2f}s | {min_time:.2f}s | {max_time:.2f}s | "
                f"{summary['successful_queries']}/{summary['total_queries']} |"
            )

        return "\n".join(lines)

    def _generate_query_table(self) -> str:
        """Generate query-by-query comparison table"""
        lines = ["| Query | Delta | Iceberg | Hudi | Fastest | Speedup |"]
        lines.append("|-------|-------|---------|------|---------|---------|")

        # Get all queries from first framework
        queries_dict = self.data[self.frameworks[0]]["gold"]["queries"]
        queries = list(queries_dict.values()) if isinstance(queries_dict, dict) else queries_dict

        for query in queries:
            query_id = query.get("query_id", "")
            query_name = query.get("query_name", query_id)
            times = {}

            for framework in self.frameworks:
                q = self._find_query(framework, query_id)
                if q and q.get("status") == "success":
                    times[framework] = q.get("duration_seconds", 0)
                else:
                    times[framework] = None

            # Find fastest
            valid_times = {k: v for k, v in times.items() if v is not None}
            if not valid_times:
                continue

            fastest_fw = min(valid_times, key=valid_times.get)
            fastest_time = valid_times[fastest_fw]
            slowest_time = max(valid_times.values())
            speedup = slowest_time / fastest_time if fastest_time > 0 else 1

            # Format times
            delta_str = f"{times['delta']:.2f}s" if times.get('delta') else "FAIL"
            iceberg_str = f"{times['iceberg']:.2f}s" if times.get('iceberg') else "FAIL"
            hudi_str = f"{times['hudi']:.2f}s" if times.get('hudi') else "FAIL"

            lines.append(
                f"| {query_id.upper()} | {delta_str} | {iceberg_str} | {hudi_str} | "
                f"{fastest_fw.capitalize()} | {speedup:.2f}x |"
            )

        return "\n".join(lines)

    def _generate_analysis(self) -> str:
        """Generate performance analysis"""
        lines = []

        # Find fastest overall
        totals = {fw: self.data[fw]["gold"]["summary"].get("total_query_time",
                      self.data[fw]["gold"]["summary"].get("total_execution_time_seconds", 0))
                  for fw in self.frameworks}
        fastest = min(totals, key=totals.get)

        lines.append(f"**Overall Winner:** {fastest.capitalize()} ({totals[fastest]:.2f}s total)")
        lines.append("")

        # Compare each framework to the fastest
        for framework in self.frameworks:
            if framework == fastest:
                continue

            diff = totals[framework] - totals[fastest]
            pct = (diff / totals[fastest]) * 100

            lines.append(f"- **{framework.capitalize()}** is {pct:.1f}% slower than {fastest.capitalize()} (+{diff:.2f}s)")

        lines.append("")

        # Query dominance
        for framework in self.frameworks:
            queries_dict = self.data[self.frameworks[0]]["gold"]["queries"]
            queries_list = list(queries_dict.values()) if isinstance(queries_dict, dict) else queries_dict

            fastest_count = sum(1 for q in queries_list
                              if self._is_fastest(framework, q.get("query_id", q.get("query_name"))))
            total = len(self.data[framework]["gold"]["queries"])
            pct = (fastest_count / total) * 100 if total > 0 else 0

            lines.append(f"- **{framework.capitalize()}** won {fastest_count}/{total} queries ({pct:.1f}%)")

        return "\n".join(lines)

    def _generate_recommendations(self) -> str:
        """Generate recommendations based on results"""
        lines = []

        totals = {fw: self.data[fw]["gold"]["summary"].get("total_query_time",
                      self.data[fw]["gold"]["summary"].get("total_execution_time_seconds", 0))
                  for fw in self.frameworks}
        fastest = min(totals, key=totals.get)

        lines.append(f"### For Scale Factor {self.scale_factor}\n")
        lines.append(f"**Best Overall Performance:** {fastest.capitalize()}\n")

        # Framework-specific insights
        if fastest == "iceberg":
            lines.append("✅ **Apache Iceberg** offers the best query performance and is recommended for:")
            lines.append("   - Analytical workloads with complex queries")
            lines.append("   - Time-travel and schema evolution requirements")
            lines.append("   - Multi-engine access (Spark, Trino, Flink)")
        elif fastest == "delta":
            lines.append("✅ **Delta Lake** offers the best query performance and is recommended for:")
            lines.append("   - Databricks ecosystem integration")
            lines.append("   - ACID transactions with streaming data")
            lines.append("   - Mature tooling and community support")
        elif fastest == "hudi":
            lines.append("✅ **Apache Hudi** offers the best query performance and is recommended for:")
            lines.append("   - Record-level updates and CDC workloads")
            lines.append("   - Incremental processing pipelines")
            lines.append("   - Fine-grained data management")

        lines.append("\n**Trade-offs to Consider:**\n")

        # Hudi analysis
        hudi_total = totals.get("hudi", 0)
        if hudi_total > 0 and fastest != "hudi":
            diff_pct = ((hudi_total - totals[fastest]) / totals[fastest]) * 100
            lines.append(f"- **Hudi** is {diff_pct:.1f}% slower but excels at:")
            lines.append("  - Incremental ETL and CDC")
            lines.append("  - Record-level operations (updates/deletes)")
            lines.append("  - Smaller batch sizes and streaming ingestion")

        return "\n".join(lines)

    def _find_query(self, framework: str, query_id: str) -> Optional[Dict]:
        """Find a query by ID in framework data"""
        queries = self.data[framework]["gold"]["queries"]

        # Handle dict structure
        if isinstance(queries, dict):
            return queries.get(query_id)

        # Handle list structure
        for q in queries:
            if q.get("query_id") == query_id or q.get("query_name") == query_id:
                return q
        return None

    def _is_fastest(self, framework: str, query_id: str) -> bool:
        """Check if this framework was fastest for this query"""
        times = {}
        for fw in self.frameworks:
            q = self._find_query(fw, query_id)
            if q and q.get("status") == "success":
                times[fw] = q.get("duration_seconds", q.get("execution_time_seconds", 0))

        if not times or framework not in times:
            return False

        return times[framework] == min(times.values())

    def _is_slowest(self, framework: str, query_id: str) -> bool:
        """Check if this framework was slowest for this query"""
        times = {}
        for fw in self.frameworks:
            q = self._find_query(fw, query_id)
            if q and q.get("status") == "success":
                times[fw] = q.get("duration_seconds", q.get("execution_time_seconds", 0))

        if not times or framework not in times:
            return False

        return times[framework] == max(times.values())

    def save_report(self, content: str) -> Path:
        """Save report to file"""
        self.reports_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"benchmark_sf{self.scale_factor}_{timestamp}.md"
        filepath = self.reports_dir / filename

        with open(filepath, 'w') as f:
            f.write(content)

        return filepath


def main():
    if len(sys.argv) != 2:
        print("Usage: python scripts/generate_report.py <scale_factor>")
        print("Example: python scripts/generate_report.py 3")
        sys.exit(1)

    try:
        scale_factor = int(sys.argv[1])
    except ValueError:
        print(f"Error: Scale factor must be an integer, got '{sys.argv[1]}'")
        sys.exit(1)

    print(f"\n{'='*60}")
    print(f"  Lakehouse Benchmark Report Generator")
    print(f"{'='*60}\n")

    reporter = BenchmarkReporter(scale_factor)

    # Load metrics
    if not reporter.load_metrics():
        print("\n❌ Failed to load metrics. Please ensure benchmark has been run for this scale factor.")
        sys.exit(1)

    # Generate report
    print(f"\n📝 Generating report...")
    report_content = reporter.generate_markdown_report()

    # Save report
    report_path = reporter.save_report(report_content)
    print(f"\n✅ Report saved to: {report_path}")

    # Also print to console
    print(f"\n{'='*60}")
    print("REPORT PREVIEW")
    print(f"{'='*60}\n")
    print(report_content)
    print(f"\n{'='*60}\n")


if __name__ == "__main__":
    main()

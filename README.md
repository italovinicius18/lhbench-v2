# Modern Data Lakehouse Pipeline

[![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=Apache%20Airflow&logoColor=white)](https://airflow.apache.org/)
[![Apache Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?style=for-the-badge&logo=Apache%20Spark&logoColor=white)](https://spark.apache.org/)
[![Apache Iceberg](https://img.shields.io/badge/Apache%20Iceberg-0888FF?style=for-the-badge&logo=apache&logoColor=white)](https://iceberg.apache.org/)
[![MinIO](https://img.shields.io/badge/MinIO-C72C48?style=for-the-badge&logo=minio&logoColor=white)](https://min.io/)
[![Trino](https://img.shields.io/badge/Trino-DD00A1?style=for-the-badge&logo=trino&logoColor=white)](https://trino.io/)

Um pipeline de dados moderno e escalÃ¡vel implementando a arquitetura Medallion (Bronze â†’ Silver â†’ Gold) usando tecnologias de ponta do ecossistema Apache.

## ğŸ—ï¸ Arquitetura

```mermaid
graph TD
    A[Dados SintÃ©ticos] --> B[Bronze Layer - CSV]
    B --> C[Silver Layer - Iceberg Tables]
    C --> D[Gold Layer - Analytics]
    
    subgraph "Storage"
        E[MinIO S3-Compatible]
    end
    
    subgraph "Processing"
        F[Apache Spark]
        G[Apache Airflow]
    end
    
    subgraph "Metadata"
        H[Hive Metastore]
        I[MariaDB]
    end
    
    subgraph "Query Engine"
        J[Trino]
    end
    
    subgraph "Visualization"
        K[Apache Superset]
    end
    
    B --> E
    C --> E
    D --> E
    F --> C
    F --> D
    G --> F
    H --> I
    J --> H
    K --> J
```

## ğŸ¯ CaracterÃ­sticas Principais

### ğŸ“Š Arquitetura Medallion
- **Bronze**: Dados brutos em formato CSV particionados por batch
- **Silver**: Tabelas Iceberg com schema estruturado e qualidade de dados
- **Gold**: AgregaÃ§Ãµes e mÃ©tricas analÃ­ticas para consumo

### ğŸ”§ Stack TecnolÃ³gico
- **OrquestraÃ§Ã£o**: Apache Airflow com Astronomer CLI
- **Processamento**: Apache Spark (PySpark) 
- **Armazenamento**: Apache Iceberg sobre MinIO (S3-compatible)
- **Metadados**: Hive Metastore com MariaDB
- **Query Engine**: Trino para consultas analÃ­ticas
- **VisualizaÃ§Ã£o**: Apache Superset
- **ContainerizaÃ§Ã£o**: Docker Compose

### ğŸš€ Funcionalidades
- **Multi-formato**: Suporte a Parquet, ORC e Avro no Iceberg
- **Processamento em Lote**: IngestÃ£o automatizada a cada 10 minutos
- **Dados SintÃ©ticos**: GeraÃ§Ã£o automÃ¡tica de dados financeiros realistas
- **Upserts**: Merge incremental com deduplicaÃ§Ã£o
- **Particionamento**: EstratÃ©gias otimizadas por formato
- **Monitoramento**: Dashboards e mÃ©tricas de pipeline

## ğŸ“ Estrutura do Projeto

```
modern-data-lakehouse/
â”œâ”€â”€ dags/                          # DAGs do Airflow
â”‚   â”œâ”€â”€ 1_generate_bronze_batch.py # GeraÃ§Ã£o de dados sintÃ©ticos
â”‚   â”œâ”€â”€ 2_bronze_to_silver.py      # Processamento Bronze â†’ Silver
â”‚   â””â”€â”€ 3_silver_to_gold.py        # Analytics Silver â†’ Gold
â”œâ”€â”€ config_trino/                  # ConfiguraÃ§Ãµes do Trino
â”‚   â”œâ”€â”€ catalog/
â”‚   â”‚   â””â”€â”€ iceberg.properties     # CatÃ¡logo Iceberg
â”‚   â”œâ”€â”€ config.properties
â”‚   â”œâ”€â”€ jvm.config
â”‚   â””â”€â”€ node.properties
â”œâ”€â”€ config_hive/                   # ConfiguraÃ§Ãµes Hive Metastore
â”‚   â””â”€â”€ metastore-site.xml
â”œâ”€â”€ docker-compose.override.yml    # DefiniÃ§Ã£o dos serviÃ§os
â”œâ”€â”€ airflow_settings.yaml         # ConfiguraÃ§Ãµes Airflow
â”œâ”€â”€ requirements.txt              # DependÃªncias Python
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### PrÃ©-requisitos
- Docker Desktop
- Docker Compose
- Astronomer CLI
- 8GB+ RAM disponÃ­vel
- 20GB+ espaÃ§o em disco

### 1. ConfiguraÃ§Ã£o Inicial

```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd lakehouse-file-format-compare

# Inicializar projeto Astronomer
astro dev init

# Criar diretÃ³rio para dados MinIO
mkdir -p ~/minio-data  # Ajuste conforme seu sistema
```

### 2. Iniciar ServiÃ§os

```bash
# Subir toda a infraestrutura
astro dev start

# Verificar status dos serviÃ§os
docker ps
```

### 3. Acessar Interfaces

| ServiÃ§o | URL | Credenciais |
|---------|-----|-------------|
| Airflow | http://localhost:8080 | admin/admin |
| MinIO Console | http://localhost:9001 | minioadmin/minioadmin |
| Trino | http://localhost:8085 | - |
| Spark Master | http://localhost:8081 | - |
| Superset | http://localhost:8088 | admin/admin |

### 4. Executar Pipeline

```bash
# 1. Gerar dimensÃµes de tempo (executar uma vez)
# No Airflow UI: trigger "generate_time_dimensions"

# 2. Gerar dados sintÃ©ticos (automatico a cada 10min)
# No Airflow UI: trigger "generate_bronze_batch"

# 3. Processar Bronze â†’ Silver (automatico a cada 12min)
# No Airflow UI: trigger "bronze_to_silver_batch"

# 4. Gerar Analytics Gold (automatico a cada 15min)
# No Airflow UI: trigger "silver_to_gold_analytics"
```

## ğŸ“Š Modelo de Dados

### DimensÃµes
- **d_customers**: Clientes e informaÃ§Ãµes pessoais
- **d_customer_identifiers**: CPF, RG e outros identificadores
- **d_products**: Produtos financeiros (cartÃ£o, conta, investimentos)
- **d_transaction_types**: Tipos de transaÃ§Ã£o (financeiras/nÃ£o-financeiras)
- **d_country/state/city**: Hierarquia geogrÃ¡fica
- **d_time/year/month/week/weekday**: DimensÃµes temporais

### Fatos
- **f_contracts**: Contratos de produtos por cliente
- **f_contract_attributes**: Atributos flexÃ­veis dos contratos
- **f_transactions**: TransaÃ§Ãµes financeiras detalhadas

### Analytics (Gold Layer)
- **monthly_balance**: Saldos mensais por contrato
- **customer_summary**: Resumo analÃ­tico por cliente
- **daily_transaction_metrics**: MÃ©tricas diÃ¡rias de transaÃ§Ãµes
- **product_ranking**: Ranking de produtos por performance

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Ajustar Volume de Dados
Edite as constantes em `dags/1_generate_bronze_batch.py`:

```python
BATCH_SIZE_CUSTOMERS = random.randint(100, 500)    # Clientes por batch
BATCH_SIZE_CONTRACTS = random.randint(200, 800)    # Contratos por batch  
BATCH_SIZE_TRANSACTIONS = random.randint(1000, 5000) # TransaÃ§Ãµes por batch
```

### Modificar Scheduling
Ajuste os schedules nos DAGs:

```python
# GeraÃ§Ã£o de dados (padrÃ£o: 10min)
schedule="*/10 * * * *"

# Bronze â†’ Silver (padrÃ£o: 12min)  
schedule="*/12 * * * *"

# Silver â†’ Gold (padrÃ£o: 15min)
schedule="*/15 * * * *"
```

### Configurar Formatos Iceberg
Os dados sÃ£o processados em 3 formatos simultaneamente:
- **Parquet**: Melhor para analytics (padrÃ£o recomendado)
- **ORC**: Otimizado para Hive/Spark
- **Avro**: Ideal para schema evolution

## ğŸ“ˆ Monitoramento e Observabilidade

### MÃ©tricas do Pipeline
- Volume de dados processados por batch
- Tempo de execuÃ§Ã£o por DAG
- Taxa de sucesso/falha
- UtilizaÃ§Ã£o de recursos Spark

### Logs e Debug
```bash
# Logs do Airflow
astro dev logs

# Logs especÃ­ficos do Spark
docker logs spark-master
docker logs spark-worker

# Logs do Trino
docker logs trino

# Debug estrutura tabelas
python scripts/debug_table_structure.py

# Validar pipeline
python scripts/validate_pipeline_readiness.py
```

### Consultas de Exemplo (Trino)

```sql
-- Ver tabelas disponÃ­veis
SHOW TABLES IN iceberg.silver;
SHOW TABLES IN iceberg.gold;

-- Analytics de transaÃ§Ãµes
SELECT 
    produto,
    SUM(volume_financeiro) as total_volume,
    COUNT(*) as total_transacoes
FROM iceberg.gold.product_ranking_parquet 
GROUP BY produto
ORDER BY total_volume DESC;

-- Saldo por cliente
SELECT 
    first_name,
    last_name, 
    saldo_total,
    total_contratos
FROM iceberg.gold.customer_summary_parquet
WHERE saldo_total > 10000
ORDER BY saldo_total DESC;
```

## ğŸ” Troubleshooting

### Problemas Comuns

**1. Erro de conexÃ£o Hive Metastore**
```bash
# Verificar se MariaDB e Hive estÃ£o rodando
docker ps | grep -E "(mariadb|hive)"

# Reiniciar Hive Metastore
docker restart hive-metastore
```

**2. Erro de memÃ³ria Spark**
```bash
# Ajustar memÃ³ria no docker-compose.override.yml
environment:
  - SPARK_WORKER_MEMORY=6G  # Aumentar conforme disponÃ­vel
```

**3. Tabelas nÃ£o aparecem no Trino**
```bash
# Verificar catÃ¡logo Iceberg
docker exec -it trino trino --server localhost:8080
> SHOW CATALOGS;
> SHOW SCHEMAS IN iceberg;
```

**4. MinIO sem espaÃ§o**
```bash
# Limpar dados antigos
docker exec -it minio mc rm --recursive --force minio/bronze/
docker exec -it minio mc rm --recursive --force minio/silver/
```

### Performance Tuning

**Spark Configuration**
```yaml
# Ajustar para seu hardware
"spark.executor.memory": "4g"
"spark.driver.memory": "2g"
"spark.executor.cores": "4"
"spark.sql.adaptive.enabled": "true"
```

**Iceberg Table Properties**
```python
# Otimizar tamanho de arquivos
"write.target-file-size-bytes": "134217728"  # 128MB
"write.parquet.compression-codec": "snappy"
```

## ğŸ“š Recursos Adicionais

### DocumentaÃ§Ã£o
- [Apache Iceberg Docs](https://iceberg.apache.org/docs/latest/)
- [Trino Iceberg Connector](https://trino.io/docs/current/connector/iceberg.html)
- [Astronomer Documentation](https://docs.astronomer.io/)

### Datasets de Exemplo
O pipeline gera automaticamente:
- 100-500 clientes por batch
- 200-800 contratos por batch
- 1.000-5.000 transaÃ§Ãµes por batch
- Dados histÃ³ricos de atÃ© 2 anos

### Schema Evolution
O Iceberg suporta evoluÃ§Ã£o de schema:
```sql
-- Adicionar nova coluna
ALTER TABLE iceberg.silver.f_transactions_parquet 
ADD COLUMN merchant_name VARCHAR;

-- Renomear coluna  
ALTER TABLE iceberg.silver.f_transactions_parquet
RENAME COLUMN amount TO transaction_amount;
```

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

**Desenvolvido com â¤ï¸ usando tecnologias open-source**